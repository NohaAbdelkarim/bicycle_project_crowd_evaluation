{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the reference solution for each question in the dataset\n",
    "def extract_references(references):\n",
    "    \n",
    "    references_df = pd.DataFrame()\n",
    "    images_list = []\n",
    "    for image in references[0]:\n",
    "       \n",
    "        try:\n",
    "            image_temp=image\n",
    "            images_list.append(image_temp)\n",
    "            reference_temp = references[0][image].copy()\n",
    "            references_df = references_df.append(pd.DataFrame(reference_temp, index = [0]))\n",
    "        except:\n",
    "            pass\n",
    "       \n",
    "    return images_list, references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference dataset\n",
    "ReferencesDataSet = [json.loads(line) for line in open('references.json', 'r', encoding = 'utf-8')]\n",
    "images_list,references_df=extract_references(ReferencesDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating NumPy array of the extracted image list\n",
    "images_list =np.array(images_list)\n",
    "# Creating NumPy array for the determined solutions\n",
    "references_list=np.array(references_df['is_bicycle'])\n",
    "# initiating a dataframe with two columns 'image' and 'label'\n",
    "references_dataset_df = pd.DataFrame(columns=['images','Label'])\n",
    "# Assign the determined image array to the images column of the created dataframe\n",
    "references_dataset_df.images=images_list\n",
    "# Assign the determined solutions array to the Label column of the created dataframe\n",
    "references_dataset_df.Label=references_list\n",
    "# Save the 'references_dataset_df' dataframe to csv file\n",
    "references_dataset_df.to_csv(r'references_dataset.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the entities from the annotator responses file\n",
    "def extract_entities(results):\n",
    "    entities_df = pd.DataFrame()\n",
    "    task_input_df = pd.DataFrame()\n",
    "    task_output_df = pd.DataFrame()\n",
    "    user_df = pd.DataFrame()\n",
    "    root_input_df = pd.DataFrame()\n",
    "    for NodeInputID in results['results']:\n",
    "        for entity in results['results'][NodeInputID]['results']:\n",
    "            entity_temp = entity.copy()\n",
    "            try: \n",
    "                if len(entity['task_input'])>0:\n",
    "                    task_input_temp = entity['task_input'].copy()\n",
    "                    task_input_df = task_input_df.append(pd.DataFrame(task_input_temp, index = [0]))\n",
    "                    entity_temp.pop('task_input', None)\n",
    "            except:\n",
    "                pass\n",
    "            try: \n",
    "                if len(entity['task_output'])>0:\n",
    "                    task_output_temp = entity['task_output'].copy()\n",
    "                    task_output_df = task_output_df.append(pd.DataFrame(task_output_temp, index = [0]))\n",
    "                    entity_temp.pop('task_output', None)\n",
    "            except:\n",
    "                pass\n",
    "            try: \n",
    "                if len(entity['user'])>0:\n",
    "                    user_temp = entity['user'].copy()\n",
    "                    user_df = user_df.append(pd.DataFrame(user_temp, index = [0]))\n",
    "                    entity_temp.pop('user', None)\n",
    "            except:\n",
    "                pass\n",
    "            try: \n",
    "                if len(entity['root_input'])>0:\n",
    "                    root_input_temp = entity['root_input'].copy()\n",
    "                    root_input_df = root_input_df.append(pd.DataFrame(root_input_temp, index = [0]))\n",
    "                    entity_temp.pop('root_input', None)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            entities_df = entities_df.append(pd.DataFrame(entity_temp, index = [0]))\n",
    "            results = pd.concat([task_input_df, entities_df, task_output_df, user_df, root_input_df], axis=1)\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotator responses dataset\n",
    "DataSet = [json.loads(line) for line in open('anonymized_project.json', 'r', encoding = 'utf-8')]\n",
    "results=DataSet[0]['results']['root_node']\n",
    "results = extract_entities(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
